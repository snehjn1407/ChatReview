{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snehjn1407/ChatReview/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4xq5IuueR6g",
        "outputId": "24848b42-18f0-4b02-9a9a-0ee5fc3aa879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Multi-Platform Product Recommendation Chatbot!\n",
            "Fetching product data...\n",
            "Amazon data shape: (1, 4)\n",
            "Amazon data columns: Index(['Name', 'Price', 'Rating', 'Description'], dtype='object')\n",
            "Flipkart data shape: (0, 0)\n",
            "Flipkart data columns: RangeIndex(start=0, stop=0, step=1)\n",
            "Combined data shape: (1, 4)\n",
            "Combined data columns: Index(['Name', 'Price', 'Rating', 'Description'], dtype='object')\n",
            "Data fetched successfully! Ask for product recommendations.\n",
            "Type 'exit' to quit.\n",
            "You: laptop\n",
            "Here are some recommendations for you:\n",
            "Name: Check each product page for other buying options.\n",
            "Price: 48,990\n",
            "Rating: 4.6 out of 5 stars.\n",
            "Reviews: No reviews available\n",
            "Description: Check each product page for other buying options.\n",
            "---\n",
            "You: phone\n",
            "Here are some recommendations for you:\n",
            "Name: Check each product page for other buying options.\n",
            "Price: 48,990\n",
            "Rating: 4.6 out of 5 stars.\n",
            "Reviews: No reviews available\n",
            "Description: Check each product page for other buying options.\n",
            "---\n",
            "You: quit\n",
            "Here are some recommendations for you:\n",
            "Name: Check each product page for other buying options.\n",
            "Price: 48,990\n",
            "Rating: 4.6 out of 5 stars.\n",
            "Reviews: No reviews available\n",
            "Description: Check each product page for other buying options.\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def scrape_amazon():\n",
        "    url = \"https://www.amazon.in/s?k=laptops&crid=15NJC9UU07FHD&sprefix=laptops%2Caps%2C243&ref=nb_sb_noss_2\"  # Replace with the actual URL\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()  # Raise HTTP errors if any\n",
        "    except requests.exceptions.MissingSchema:\n",
        "        print(\"Error: The URL is invalid or missing a schema. Please update it.\")\n",
        "        return pd.DataFrame()  # Return empty DataFrame\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract product details (replace placeholders with actual class names)\n",
        "    products = []\n",
        "    for item in soup.find_all(\"div\", class_=\"s-main-slot\"):\n",
        "        name = item.find(\"span\", class_=\"a-text-normal\").text.strip() if item.find(\"span\", class_=\"a-text-normal\") else \"Unknown\"\n",
        "        price = item.find(\"span\", class_=\"a-price-whole\").text.strip() if item.find(\"span\", class_=\"a-price-whole\") else \"Unknown\"\n",
        "        rating = item.find(\"span\", class_=\"a-icon-alt\").text.strip() if item.find(\"span\", class_=\"a-icon-alt\") else \"No ratings\"\n",
        "        description = name  # Use name as fallback description\n",
        "        products.append({\"Name\": name, \"Price\": price, \"Rating\": rating, \"Description\": description})\n",
        "\n",
        "    return pd.DataFrame(products)\n",
        "\n",
        "def scrape_flipkart():\n",
        "    url = \"https://www.flipkart.com/search?q=laptop&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract product details\n",
        "    products = []\n",
        "    for item in soup.find_all(\"div\", class_=\"<class_name>\"):\n",
        "        name = item.find(\"a\", class_=\"<name_class>\").text.strip()\n",
        "        price = item.find(\"div\", class_=\"<price_class>\").text.strip()\n",
        "        rating = item.find(\"div\", class_=\"<rating_class>\").text.strip()\n",
        "        reviews = item.find(\"span\", class_=\"<reviews_class>\").text.strip()\n",
        "        description = \"Description not available\"\n",
        "        products.append({\"Name\": name, \"Price\": price, \"Rating\": rating, \"Reviews\": reviews, \"Description\": description})\n",
        "\n",
        "    return pd.DataFrame(products)\n",
        "\n",
        "def chatbot_logic(user_query, scraped_data):\n",
        "    # Check if the DataFrame is empty or if the 'Description' column is missing\n",
        "    if scraped_data.empty or 'Description' not in scraped_data.columns:\n",
        "        print(\"Error: No valid data available for recommendations.\")\n",
        "        return pd.DataFrame()  # Return an empty DataFrame\n",
        "\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    product_vectors = vectorizer.fit_transform(scraped_data['Description'])\n",
        "    query_vector = vectorizer.transform([user_query])\n",
        "\n",
        "    similarity = cosine_similarity(query_vector, product_vectors)\n",
        "    ranked_indices = similarity.argsort()[0][::-1]\n",
        "\n",
        "    recommendations = scraped_data.iloc[ranked_indices[:5]]\n",
        "    return recommendations\n",
        "\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Multi-Platform Product Recommendation Chatbot!\")\n",
        "    print(\"Fetching product data...\")\n",
        "\n",
        "    amazon_data = scrape_amazon()\n",
        "    print(f\"Amazon data shape: {amazon_data.shape}\")\n",
        "    print(f\"Amazon data columns: {amazon_data.columns}\")\n",
        "\n",
        "    flipkart_data = scrape_flipkart()\n",
        "    print(f\"Flipkart data shape: {flipkart_data.shape}\")\n",
        "    print(f\"Flipkart data columns: {flipkart_data.columns}\")\n",
        "\n",
        "    combined_data = pd.concat([amazon_data, flipkart_data], ignore_index=True)\n",
        "    print(f\"Combined data shape: {combined_data.shape}\")\n",
        "    print(f\"Combined data columns: {combined_data.columns}\")\n",
        "\n",
        "    if combined_data.empty:\n",
        "        print(\"No data could be fetched from the platforms. Please check your connections or URLs.\")\n",
        "        return\n",
        "\n",
        "    print(\"Data fetched successfully! Ask for product recommendations.\")\n",
        "    print(\"Type 'exit' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"You: \").lower()\n",
        "        if user_query == 'exit':\n",
        "            print(\"Thank you for using the chatbot. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        recommendations = chatbot_logic(user_query, combined_data)\n",
        "        if recommendations.empty:\n",
        "            print(\"Sorry, no matching products found.\")\n",
        "        else:\n",
        "            print(\"Here are some recommendations for you:\")\n",
        "            for _, product in recommendations.iterrows():\n",
        "                print(f\"Name: {product['Name']}\")\n",
        "                print(f\"Price: {product['Price']}\")\n",
        "                print(f\"Rating: {product['Rating']}\")\n",
        "                # Use .get() to safely access 'Reviews' column in case it's missing in some rows\n",
        "                print(f\"Reviews: {product.get('Reviews', 'No reviews available')}\")\n",
        "                print(f\"Description: {product['Description']}\")\n",
        "                print(\"---\")\n",
        "\n",
        "# Run the chatbot\n",
        "# Note: Replace placeholders with actual scraping logic based on inspected HTML structures\n",
        "chatbot()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def scrape_amazon():\n",
        "    url = \"https://www.amazon.in/s?k=laptops\"  # Replace with the actual URL\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()  # Raise HTTP errors if any\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return pd.DataFrame(columns=[\"Name\", \"Price\", \"Rating\", \"Description\"])  # Return empty DataFrame with required columns\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    products = []\n",
        "    for item in soup.find_all(\"div\", class_=\"s-main-slot s-result-list s-search-results sg-row\"):\n",
        "        name = item.find(\"span\", class_=\"a-text-normal\").text.strip() if item.find(\"span\", class_=\"a-text-normal\") else \"Unknown\"\n",
        "        price = item.find(\"span\", class_=\"a-price-whole\").text.strip() if item.find(\"span\", class_=\"a-price-whole\") else \"Unknown\"\n",
        "        rating = item.find(\"span\", class_=\"a-icon-alt\").text.strip() if item.find(\"span\", class_=\"a-icon-alt\") else \"No ratings\"\n",
        "        description = name  # Use name as fallback description\n",
        "        products.append({\"Name\": name, \"Price\": price, \"Rating\": rating, \"Description\": description})\n",
        "\n",
        "    return pd.DataFrame(products)\n",
        "\n",
        "def scrape_flipkart():\n",
        "    url = \"https://www.flipkart.com/search?q=jeans\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return pd.DataFrame(columns=[\"Name\", \"Price\", \"Rating\", \"Reviews\", \"Description\"])  # Return empty DataFrame\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    products = []\n",
        "    for item in soup.find_all(\"div\", class_=\"_2kHMtA\"):  # Flipkart product container class\n",
        "        name = item.find(\"div\", class_=\"_4rR01T\").text.strip() if item.find(\"div\", class_=\"_4rR01T\") else \"Unknown\"\n",
        "        price = item.find(\"div\", class_=\"_30jeq3 _1_WHN1\").text.strip() if item.find(\"div\", class_=\"_30jeq3 _1_WHN1\") else \"Unknown\"\n",
        "        rating = item.find(\"div\", class_=\"_3LWZlK\").text.strip() if item.find(\"div\", class_=\"_3LWZlK\") else \"No ratings\"\n",
        "        reviews = item.find(\"span\", class_=\"_2_R_DZ\").text.strip() if item.find(\"span\", class_=\"_2_R_DZ\") else \"No reviews\"\n",
        "        description = name  # Use name as fallback description\n",
        "        products.append({\"Name\": name, \"Price\": price, \"Rating\": rating, \"Reviews\": reviews, \"Description\": description})\n",
        "\n",
        "    return pd.DataFrame(products)\n",
        "\n",
        "def chatbot_logic(user_query, scraped_data):\n",
        "    if scraped_data.empty:\n",
        "        return pd.DataFrame()  # Return empty DataFrame if no data available\n",
        "\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    product_vectors = vectorizer.fit_transform(scraped_data['Description'])\n",
        "    query_vector = vectorizer.transform([user_query])\n",
        "\n",
        "    similarity = cosine_similarity(query_vector, product_vectors)\n",
        "    ranked_indices = similarity.argsort()[0][::-1]\n",
        "\n",
        "    recommendations = scraped_data.iloc[ranked_indices[:5]]\n",
        "    return recommendations\n",
        "\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Multi-Platform Product Recommendation Chatbot!\")\n",
        "    print(\"Fetching product data...\")\n",
        "\n",
        "    amazon_data = scrape_amazon()\n",
        "    flipkart_data = scrape_flipkart()\n",
        "    combined_data = pd.concat([amazon_data, flipkart_data], ignore_index=True)\n",
        "\n",
        "    if combined_data.empty:\n",
        "        print(\"No data could be fetched from the platforms. Please check your connections or URLs.\")\n",
        "        return\n",
        "\n",
        "    print(\"Data fetched successfully! Ask for product recommendations.\")\n",
        "    print(\"Type 'exit' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"You: \").lower()\n",
        "        if user_query == 'exit':\n",
        "            print(\"Thank you for using the chatbot. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        recommendations = chatbot_logic(user_query, combined_data)\n",
        "        if recommendations.empty:\n",
        "            print(\"Sorry, no matching products found.\")\n",
        "        else:\n",
        "            print(\"Here are some recommendations for you:\")\n",
        "            for _, product in recommendations.iterrows():\n",
        "                print(f\"Name: {product['Name']}\")\n",
        "                print(f\"Price: {product['Price']}\")\n",
        "                print(f\"Rating: {product['Rating']}\")\n",
        "                print(f\"Reviews: {product.get('Reviews', 'No reviews available')}\")\n",
        "                print(f\"Description: {product['Description']}\")\n",
        "                print(\"---\")\n",
        "\n",
        "# Run the chatbot\n",
        "chatbot()\n"
      ],
      "metadata": {
        "id": "QsfbYXtSsAB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def scrape_amazon():\n",
        "    url = \"hhttps://www.amazon.in/?&tag=googhydrabk1-21&ref=pd_sl_5szpgfto9i_e&adgrpid=155259813593&hvpone=&hvptwo=&hvadid=713930225169&hvpos=&hvnetw=g&hvrand=12019880781526199765&hvqmt=e&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9302648&hvtargid=kwd-64107830&hydadcr=14452_2402225&gad_source=1\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching Amazon data: {e}\")\n",
        "        return pd.DataFrame(columns=[\"Name\", \"Price\", \"Rating\", \"Description\"])  # Empty DataFrame with required columns\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    products = []\n",
        "    for item in soup.find_all(\"div\", class_=\"s-main-slot s-result-list s-search-results sg-row\"):\n",
        "        name = item.find(\"span\", class_=\"a-text-normal\").text.strip() if item.find(\"span\", class_=\"a-text-normal\") else \"Unknown\"\n",
        "        price = item.find(\"span\", class_=\"a-price-whole\").text.strip() if item.find(\"span\", class_=\"a-price-whole\") else \"Unknown\"\n",
        "        rating = item.find(\"span\", class_=\"a-icon-alt\").text.strip() if item.find(\"span\", class_=\"a-icon-alt\") else \"No ratings\"\n",
        "        description = name  # Use name as fallback description\n",
        "        products.append({\"Name\": name, \"Price\": price, \"Rating\": rating, \"Description\": description})\n",
        "\n",
        "    return pd.DataFrame(products)\n",
        "\n",
        "def scrape_flipkart():\n",
        "    url = \"https://www.flipkart.com/?s_kwcid=AL!739!3!582822043580!b!!g!!flipkart&gclsrc=aw.ds&&semcmpid=sem_8024046704_brand_exe_buyers_goog&gad_source=1&gclid=CjwKCAiAxea5BhBeEiwAh4t5K4IKFKBYhyBwoZKWGDl6hxDD8_hWR712MsW69KYgtAjXEd99pLDYKhoCeXIQAvD_BwE\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching Flipkart data: {e}\")\n",
        "        return pd.DataFrame(columns=[\"Name\", \"Price\", \"Rating\", \"Reviews\", \"Description\"])  # Empty DataFrame\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    products = []\n",
        "    for item in soup.find_all(\"div\", class_=\"_2kHMtA\"):  # Flipkart product container class\n",
        "        name = item.find(\"div\", class_=\"_4rR01T\").text.strip() if item.find(\"div\", class_=\"_4rR01T\") else \"Unknown\"\n",
        "        price = item.find(\"div\", class_=\"_30jeq3 _1_WHN1\").text.strip() if item.find(\"div\", class_=\"_30jeq3 _1_WHN1\") else \"Unknown\"\n",
        "        rating = item.find(\"div\", class_=\"_3LWZlK\").text.strip() if item.find(\"div\", class_=\"_3LWZlK\") else \"No ratings\"\n",
        "        reviews = item.find(\"span\", class_=\"_2_R_DZ\").text.strip() if item.find(\"span\", class_=\"_2_R_DZ\") else \"No reviews\"\n",
        "        description = name  # Use name as fallback description\n",
        "        products.append({\"Name\": name, \"Price\": price, \"Rating\": rating, \"Reviews\": reviews, \"Description\": description})\n",
        "\n",
        "    return pd.DataFrame(products)\n",
        "\n",
        "def chatbot_logic(user_query, scraped_data):\n",
        "    if scraped_data.empty:\n",
        "        return pd.DataFrame()  # Return empty DataFrame if no data is available\n",
        "\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    product_vectors = vectorizer.fit_transform(scraped_data['Description'])\n",
        "    query_vector = vectorizer.transform([user_query])\n",
        "\n",
        "    similarity = cosine_similarity(query_vector, product_vectors)\n",
        "    ranked_indices = similarity.argsort()[0][::-1]\n",
        "\n",
        "    recommendations = scraped_data.iloc[ranked_indices[:5]]\n",
        "    return recommendations\n",
        "\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Multi-Platform Product Recommendation Chatbot!\")\n",
        "    print(\"Fetching product data...\")\n",
        "\n",
        "    amazon_data = scrape_amazon()\n",
        "    flipkart_data = scrape_flipkart()\n",
        "    combined_data = pd.concat([amazon_data, flipkart_data], ignore_index=True)\n",
        "\n",
        "    if combined_data.empty:\n",
        "        print(\"No data could be fetched from the platforms. Please check your connections or URLs.\")\n",
        "        return\n",
        "\n",
        "    print(\"Data fetched successfully! Ask for product recommendations.\")\n",
        "    print(\"Type 'exit' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"You: \").lower()\n",
        "        if user_query == 'exit':\n",
        "            print(\"Thank you for using the chatbot. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        recommendations = chatbot_logic(user_query, combined_data)\n",
        "        if recommendations.empty:\n",
        "            print(\"Sorry, no matching products found. Try another query.\")\n",
        "        else:\n",
        "            print(\"Here are some recommendations for you:\")\n",
        "            for _, product in recommendations.iterrows():\n",
        "                print(f\"Name: {product['Name']}\")\n",
        "                print(f\"Price: {product['Price']}\")\n",
        "                print(f\"Rating: {product['Rating']}\")\n",
        "                print(f\"Reviews: {product.get('Reviews', 'No reviews available')}\")\n",
        "                print(f\"Description: {product['Description']}\")\n",
        "                print(\"---\")\n",
        "\n",
        "# Run the chatbot\n",
        "chatbot()\n"
      ],
      "metadata": {
        "id": "eWdCunoys3Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def scrape_amazon():\n",
        "    url = \"https://www.amazon.in/s?k=laptops\"  # Corrected URL\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()  # Raise HTTP errors if any\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching Amazon data: {e}\")\n",
        "        return pd.DataFrame(columns=[\"Name\", \"Price\", \"Rating\", \"Description\"])  # Return empty DataFrame\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    products = []\n",
        "    for item in soup.find_all(\"div\", class_=\"s-main-slot s-result-list s-search-results sg-row\"):\n",
        "        name = item.find(\"span\", class_=\"a-text-normal\").text.strip() if item.find(\"span\", class_=\"a-text-normal\") else \"Unknown\"\n",
        "        price = item.find(\"span\", class_=\"a-price-whole\").text.strip() if item.find(\"span\", class_=\"a-price-whole\") else \"Unknown\"\n",
        "        rating = item.find(\"span\", class_=\"a-icon-alt\").text.strip() if item.find(\"span\", class_=\"a-icon-alt\") else \"No ratings\"\n",
        "        description = name\n",
        "        products.append({\"Name\": name, \"Price\": price, \"Rating\": rating, \"Description\": description})\n",
        "\n",
        "    return pd.DataFrame(products)\n",
        "\n",
        "def scrape_flipkart():\n",
        "    url = \"https://www.flipkart.com/search?q=jeans\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    for _ in range(3):  # Retry logic\n",
        "        try:\n",
        "            response = requests.get(url, headers=headers)\n",
        "            response.raise_for_status()\n",
        "            break\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching Flipkart data: {e}\")\n",
        "            time.sleep(5)  # Wait before retrying\n",
        "    else:\n",
        "        return pd.DataFrame(columns=[\"Name\", \"Price\", \"Rating\", \"Reviews\", \"Description\"])  # Empty DataFrame if failed\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    products = []\n",
        "    for item in soup.find_all(\"div\", class_=\"_2kHMtA\"):\n",
        "        name = item.find(\"div\", class_=\"_4rR01T\").text.strip() if item.find(\"div\", class_=\"_4rR01T\") else \"Unknown\"\n",
        "        price = item.find(\"div\", class_=\"_30jeq3 _1_WHN1\").text.strip() if item.find(\"div\", class_=\"_30jeq3 _1_WHN1\") else \"Unknown\"\n",
        "        rating = item.find(\"div\", class_=\"_3LWZlK\").text.strip() if item.find(\"div\", class_=\"_3LWZlK\") else \"No ratings\"\n",
        "        reviews = item.find(\"span\", class_=\"_2_R_DZ\").text.strip() if item.find(\"span\", class_=\"_2_R_DZ\") else \"No reviews\"\n",
        "        description = name\n",
        "        products.append({\"Name\": name, \"Price\": price, \"Rating\": rating, \"Reviews\": reviews, \"Description\": description})\n",
        "\n",
        "    return pd.DataFrame(products)\n",
        "\n",
        "# Run the chatbot\n",
        "chatbot()\n"
      ],
      "metadata": {
        "id": "4YyYPv-CtWm8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}